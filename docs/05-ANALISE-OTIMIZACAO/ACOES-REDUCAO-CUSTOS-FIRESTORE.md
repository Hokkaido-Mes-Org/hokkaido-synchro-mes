# ğŸ”¥ AÃ§Ãµes para OtimizaÃ§Ã£o e ReduÃ§Ã£o de Custos â€” Cloud Firestore

**Data:** Fevereiro 2026  
**Sistema:** Hokkaido MES  
**Objetivo:** CatÃ¡logo de aÃ§Ãµes possÃ­veis para reduÃ§Ã£o contÃ­nua de custos no Firestore  
**Contexto:** Fases 1-3 de otimizaÃ§Ã£o jÃ¡ implementadas (~1,2M â†’ ~390K leituras/dia, reduÃ§Ã£o de 67%)

---

## ğŸ“Š SituaÃ§Ã£o Atual (pÃ³s-otimizaÃ§Ãµes)

| MÃ©trica | Valor Atual |
|---------|-------------|
| Leituras estimadas/dia | ~390.000 |
| ColeÃ§Ãµes Firestore | 29 |
| Chamadas `.get()` diretas (sem cache) | ~90 em script.js + ~25 em controllers |
| Listeners `onSnapshot` ativos | 3 (active_downtimes, pcp_messages Ã—2) |
| Pollings com leitura Firebase | 6 intervalos ativos |
| Full collection reads (sem `.where()`) | **18 locais** |
| Custo mensal estimado | ~$12-25 |

### Maiores Consumidores Remanescentes

| # | Fonte | Leit./Dia | % do Total |
|---|-------|-----------|-----------|
| 1 | Dashboard TV â€” `loadRealTimeData` (60s poll Ã— 4 coleÃ§Ãµes) | ~86.400 | 22% |
| 2 | `pollActiveDowntimes` â€” script.js + planning.controller (300s) | ~17.280 | 4% |
| 3 | `calculateAllKPIs` â€” advanced-kpis.js (60min Ã— 4 coleÃ§Ãµes) | ~3.840 | 1% |
| 4 | NavegaÃ§Ã£o entre abas (leituras sob demanda) | ~280.000 | 72% |

---

## ğŸ“‹ CatÃ¡logo de AÃ§Ãµes

### Legenda de EsforÃ§o e Impacto

| SÃ­mbolo | EsforÃ§o | Impacto |
|---------|---------|---------|
| âš¡ | < 2 horas | ğŸŸ¢ Baixo (< 5% reduÃ§Ã£o) |
| ğŸ”§ | 2-8 horas | ğŸŸ¡ MÃ©dio (5-20% reduÃ§Ã£o) |
| ğŸ—ï¸ | 1-3 dias | ğŸ”´ Alto (> 20% reduÃ§Ã£o) |
| ğŸ¢ | 1+ semana | ğŸ”´ğŸ”´ Muito Alto (> 40% reduÃ§Ã£o) |

---

## NÃVEL 1 â€” Quick Wins (sem risco, implementaÃ§Ã£o imediata)

### 1.1 âš¡ Eliminar full collection reads remanescentes â†’ ğŸŸ¡ MÃ©dio

**Problema:** 18 locais ainda fazem `.get()` sem `.where()`, lendo a coleÃ§Ã£o inteira.

| Arquivo | Linha | ColeÃ§Ã£o | SoluÃ§Ã£o |
|---------|-------|---------|---------|
| script.js | L1203 | `production_orders` | Usar `getProductionOrdersCached()` |
| script.js | L1389 | `active_downtimes` | Usar `getActiveDowntimesCached()` |
| script.js | L1455 | `machine_priorities` | Usar `getMachinePrioritiesCached()` |
| script.js | L10436 | `production_orders` | Adicionar `.limit(100)` + `.where('status','!=','finalizada')` |
| launch.controller.js | L276, L3706 | `active_downtimes` | Usar `FirebaseCacheService.getActiveDowntimes()` |
| launch.controller.js | L3581 | `production_orders` | Usar `FirebaseCacheService.getProductionOrders()` |
| orders.controller.js | L45 | `production_orders` | Adicionar `.limit(200)` + filtro de status |
| pcp.controller.js | L432 | `active_downtimes` | Usar `FirebaseCacheService.getActiveDowntimes()` |
| downtime-grid.controller.js | L88 | `active_downtimes` | Usar `FirebaseCacheService.getActiveDowntimes()` |
| tooling.controller.js | L103 | `ferramentaria_moldes` | JÃ¡ cacheado (verificar se cache estÃ¡ ativo) |
| planning.controller.js | L1314 | `production_orders` | Adicionar `.limit(200)` |
| reports.controller.js | L92 | `production_orders` | JÃ¡ tem `.limit(2000)` â€” reduzir para `.limit(500)` |
| dashboard-tv.html | L3633, L3871 | `active_downtimes` | Usar dados do `onSnapshot` jÃ¡ ativo (L3075) |
| firebase-cache.service.js | L32, L103, L161 | vÃ¡rios | SÃ£o os prÃ³prios cache methods â€” OK |

**Economia estimada:** ~50.000-80.000 leituras/dia  
**Risco:** Nenhum â€” apenas redirecionar para funÃ§Ãµes de cache existentes

---

### 1.2 âš¡ Dashboard TV â€” reutilizar `onSnapshot` em vez de polling â†’ ğŸŸ¡ MÃ©dio

**Problema:** `dashboard-tv.html` tem um `onSnapshot` full collection em `active_downtimes` (L3075) E TAMBÃ‰M faz `.get()` full collection nos mesmos dados em L3633 e L3871.

**SoluÃ§Ã£o:** Armazenar os dados do `onSnapshot` em variÃ¡vel local e reutilizar:

```javascript
// Em vez de:
const snapshot = await db.collection('active_downtimes').get();

// Usar a variÃ¡vel populada pelo onSnapshot:
const downtimes = window._activeDowntimesSnapshot || [];
```

**Economia estimada:** ~2.880 leituras/dia por TV  
**Risco:** Nenhum

---

### 1.3 âš¡ Unificar polling duplicado de `active_downtimes` â†’ ğŸŸ¢ Baixo

**Problema:** `pollActiveDowntimes` roda em dois locais independentes com 300s:
- `script.js` L11288
- `planning.controller.js` L2515

Se ambos estiverem ativos simultaneamente, dobra as leituras.

**SoluÃ§Ã£o:** Verificar se o polling jÃ¡ estÃ¡ ativo antes de iniciar outro:

```javascript
if (!window._activeDowntimesPollActive) {
    window._activeDowntimesPollActive = true;
    setInterval(pollActiveDowntimes, 300000);
}
```

Ou centralizar no `StateManager` como fonte Ãºnica:

```javascript
// StateManager.startPolling('activeDowntimes', fetchFn, 300000);
```

**Economia estimada:** ~8.640 leituras/dia  
**Risco:** Muito baixo

---

### 1.4 âš¡ Adicionar `visibilitychange` no Dashboard TV â†’ ğŸŸ¡ MÃ©dio

**Problema:** O polling de 60s em `loadRealTimeData` continua rodando mesmo quando a TV estÃ¡ com tela desligada ou o navegador estÃ¡ em segundo plano.

**SoluÃ§Ã£o:**

```javascript
document.addEventListener('visibilitychange', () => {
    if (document.hidden) {
        clearInterval(window._dashboardTVPollInterval);
    } else {
        loadRealTimeData(); // refresh imediato
        window._dashboardTVPollInterval = setInterval(loadRealTimeData, 60000);
    }
});
```

**Economia estimada:** ~20.000-40.000 leituras/dia (depende do uso)  
**Risco:** Nenhum

---

## NÃVEL 2 â€” OtimizaÃ§Ãµes Estruturais (mÃ©dio esforÃ§o)

### 2.1 ğŸ”§ Implementar invalidaÃ§Ã£o de cache em writes â†’ ğŸŸ¡ MÃ©dio

**Problema:** ApÃ³s salvar/editar/excluir um documento, o cache continua servindo dados antigos atÃ© o TTL expirar. Algumas funÃ§Ãµes fazem `forceRefresh`, mas nÃ£o hÃ¡ padrÃ£o consistente.

**SoluÃ§Ã£o:** Criar um wrapper de escrita que invalida caches automaticamente:

```javascript
// src/utils/write-invalidation.js
const CACHE_KEYS_BY_COLLECTION = {
    'production_entries': ['productionEntries', 'prod_*'],
    'production_orders': ['productionOrders'],
    'planning':          ['planning', 'plan_*'],
    'active_downtimes':  ['activeDowntimes'],
    'downtime_entries':  ['downtimeEntries', 'down_*'],
};

async function writeAndInvalidate(collectionName, operation) {
    const result = await operation(); // .add(), .update(), .delete()
    
    const keys = CACHE_KEYS_BY_COLLECTION[collectionName] || [];
    keys.forEach(key => {
        CacheManager.invalidate(key);
        DataStore.invalidate(key);
        StateManager.invalidate(key);
    });
    
    return result;
}
```

**BenefÃ­cio:** Elimina reads desnecessÃ¡rios de refresh pÃ³s-escrita  
**Economia estimada:** ~15.000-30.000 leituras/dia  
**Risco:** Baixo â€” precisa testar fluxos de ediÃ§Ã£o

---

### 2.2 ğŸ”§ Prefetch de dados por aba (tab-aware loading) â†’ ğŸŸ¡ MÃ©dio

**Problema:** Cada aba carrega seus dados independentemente ao ser acessada, sem reaproveitar dados jÃ¡ carregados.

**SoluÃ§Ã£o:** Ao trocar de aba, prÃ©-carregar dados da aba adjacente em background:

```javascript
function onTabChange(currentTab) {
    const tabDataMap = {
        'lancamento': ['planning', 'active_downtimes', 'production_entries'],
        'analise':    ['production_entries', 'downtime_entries', 'planning'],
        'pcp':        ['active_downtimes', 'planning', 'production_orders'],
        'ordens':     ['production_orders'],
    };
    
    const collections = tabDataMap[currentTab] || [];
    collections.forEach(col => {
        // Pre-warm cache se nÃ£o existir
        if (!CacheManager.has(col)) {
            CacheManager.fetchCollection(col);
        }
    });
}
```

**Economia estimada:** ~20.000 leituras/dia  
**Risco:** Baixo

---

### 2.3 ğŸ”§ Consolidar queries de relatÃ³rios com ranges compartilhados â†’ ğŸŸ¡ MÃ©dio

**Problema:** Sub-abas de AnÃ¡lise (ProduÃ§Ã£o, EficiÃªncia, Perdas, Paradas) consultam as mesmas coleÃ§Ãµes com os mesmos filtros de data, mas separadamente. Cache inline ajuda mas cada sub-aba tem chave diferente se o perÃ­odo for ligeiramente diferente.

**SoluÃ§Ã£o:** Normalizar perÃ­odos para intervalos padrÃ£o (hoje, Ãºltimos 7 dias, Ãºltimos 30 dias, mÃªs corrente) e usar chave de cache compartilhada:

```javascript
function normalizePeriod(startDate, endDate) {
    const today = new Date().toISOString().split('T')[0];
    if (startDate === today && endDate === today) return 'today';
    // ... outros perÃ­odos padrÃ£o
    return `${startDate}_${endDate}`;
}
```

**Economia estimada:** ~10.000-20.000 leituras/dia  
**Risco:** Baixo

---

### 2.4 ğŸ”§ PaginaÃ§Ã£o em coleÃ§Ãµes grandes â†’ ğŸŸ¡ MÃ©dio

**Problema:** `production_orders` Ã© carregada inteira em mÃºltiplos locais. Ã€ medida que o nÃºmero de OPs cresce, cada leitura fica mais cara.

**Locais afetados:**
- `orders.controller.js` L45 â€” `.orderBy('createdAt', 'desc').get()` â€” sem limit
- `planning.controller.js` L1314 â€” `.orderBy('createdAt', 'desc')` â€” sem limit
- `script.js` L10436 â€” `.orderBy('createdAt', 'desc')` â€” sem limit

**SoluÃ§Ã£o:**

```javascript
// Adicionar limit + filtro de status
db.collection('production_orders')
    .where('status', '!=', 'finalizada')
    .orderBy('createdAt', 'desc')
    .limit(100)
    .get();

// Para visualizar finalizadas: paginaÃ§Ã£o sob demanda
db.collection('production_orders')
    .orderBy('createdAt', 'desc')
    .startAfter(lastDoc)
    .limit(50)
    .get();
```

**Economia estimada:** Proporcional ao crescimento â€” ~500 docs Ã— 10 readers Ã— 3 calls = ~15.000 leituras/dia atuais â†’ ~3.000 com paginaÃ§Ã£o  
**Risco:** MÃ©dio â€” precisa ajustar UI para suportar paginaÃ§Ã£o

---

### 2.5 ğŸ”§ Dashboard de monitoramento de consumo (Fase 3 pendente) â†’ ğŸŸ¢ Baixo

**Problema:** NÃ£o hÃ¡ visibilidade em tempo real do consumo de leituras. `FirebaseMonitor` e `DataStore.getStats()` existem mas nÃ£o sÃ£o exibidos.

**SoluÃ§Ã£o:** Adicionar painel na aba Admin com:
- Total de leituras desde login
- Cache hit ratio
- Top 5 coleÃ§Ãµes mais lidas
- Alertas quando consumo excede threshold

```javascript
// Exibir no footer ou aba admin
function renderFirebaseStats() {
    const stats = window.FirebaseMonitor?.getStats?.() 
                || window.DataStore?.getStats?.() 
                || {};
    
    document.getElementById('firebase-stats').innerHTML = `
        ğŸ“Š Leituras: ${stats.total || 0} | 
        Cache: ${stats.cacheHits || 0} hits | 
        Ratio: ${((stats.cacheHits / Math.max(stats.total, 1)) * 100).toFixed(1)}%
    `;
}
```

**Economia:** Indireta â€” permite medir impacto de otimizaÃ§Ãµes futuras  
**Risco:** Nenhum

---

## NÃVEL 3 â€” OtimizaÃ§Ãµes AvanÃ§adas (alto impacto, maior esforÃ§o)

### 3.1 ğŸ—ï¸ Migrar `active_downtimes` para Realtime Database â†’ ğŸ”´ Alto

**Problema:** `active_downtimes` Ã© a coleÃ§Ã£o mais acessada (polling 300s em 2+ locais, `onSnapshot` no Dashboard TV, `.get()` em 12+ locais). Firestore cobra por documento lido; Realtime Database cobra por dados transferidos (GB).

**Dados da coleÃ§Ã£o:**
- ~26 documentos (1 por mÃ¡quina)
- ~2-3 KB por documento
- Total: ~65 KB por leitura completa

**CÃ¡lculo de custo comparativo:**

| MÃ©trica | Firestore | Realtime DB |
|---------|-----------|-------------|
| Custo por leitura | $0.06/100K docs | â€” |
| Custo por GB transferido | â€” | $1/GB |
| Leituras/dia atuais | ~50.000 (26 docs cada) | â€” |
| Dados transferidos/dia | â€” | ~3.25 GB |
| Custo/dia | ~$0.78 | ~$3.25 |
| Custo/mÃªs | ~$23.40 | ~$97.50 |

**âš ï¸ RESULTADO:** Para este volume de dados, Realtime Database Ã© **mais caro** que Firestore. Esta aÃ§Ã£o **NÃƒO Ã© recomendada** a menos que o volume de documentos cresÃ§a significativamente (>200 docs na coleÃ§Ã£o).

**Alternativa recomendada:** Manter no Firestore mas otimizar via `onSnapshot` (ver aÃ§Ã£o 3.2).

---

### 3.2 ğŸ—ï¸ Converter pollings de `active_downtimes` para `onSnapshot` compartilhado â†’ ğŸ”´ Alto

**Problema:** MÃºltiplos pollings (setInterval 300s) fazem `.get()` na mesma coleÃ§Ã£o. Cada poll lÃª todos os 26 documentos. Com `onSnapshot`, o Firestore cobra apenas 1 leitura por documento alterado apÃ³s a leitura inicial.

**SituaÃ§Ã£o atual:**
- `script.js` L11288 â€” polling 300s â†’ `.get()` full
- `planning.controller.js` L2515 â€” polling 300s â†’ `.get()` full
- `dashboard-tv.html` L3075 â€” jÃ¡ usa `onSnapshot` âœ…
- Reads sob demanda em 6+ locais â€” `.get()` full cada vez

**SoluÃ§Ã£o:** Criar um listener `onSnapshot` Ãºnico e compartilhado:

```javascript
// src/services/active-downtimes-live.service.js
class ActiveDowntimesLiveService {
    constructor() {
        this._data = [];
        this._subscribers = [];
        this._unsubscribe = null;
    }
    
    start() {
        if (this._unsubscribe) return;
        this._unsubscribe = db.collection('active_downtimes')
            .onSnapshot(snapshot => {
                this._data = snapshot.docs.map(d => ({ id: d.id, ...d.data() }));
                this._subscribers.forEach(fn => fn(this._data));
            });
    }
    
    getData() { return this._data; }
    
    subscribe(fn) {
        this._subscribers.push(fn);
        if (this._data.length) fn(this._data); // immediate
        return () => this._subscribers = this._subscribers.filter(s => s !== fn);
    }
    
    stop() {
        this._unsubscribe?.();
        this._unsubscribe = null;
    }
}

// Uso: substituir todos os polling e .get() por:
const data = activeDowntimesLive.getData();
```

**Economia estimada:**
- Polling atual: ~17.280 leituras/dia (26 docs Ã— 288 polls/dia)
- onSnapshot: ~26 leituras iniciais + ~500 leituras/dia (apenas docs alterados)
- **Economia: ~16.750 leituras/dia (~97%)**

**Risco:** MÃ©dio â€” listener permanente pode ter problemas de reconexÃ£o; precisa de cleanup em `visibilitychange`

---

### 3.3 ğŸ—ï¸ Cloud Functions para consolidaÃ§Ã£o de dados â†’ ğŸ”´ Alto

**Problema:** RelatÃ³rios e anÃ¡lises consultam `production_entries`, `downtime_entries` e `planning` com filtros de data range. Cada consulta percorre potencialmente centenas de documentos.

**SoluÃ§Ã£o:** Criar Cloud Functions que consolidam dados diariamente:

```
Firestore Trigger: onCreate/onUpdate em production_entries
â†’ Cloud Function: consolidateProductionDaily
â†’ Escreve em: daily_production_summary/{date}
    - totalProduzido por mÃ¡quina
    - totalRefugo por mÃ¡quina
    - OEE consolidado
    - totalSetup, totalParadas
```

**Collections de resumo sugeridas:**

| ColeÃ§Ã£o | Documento | Dados |
|---------|-----------|-------|
| `daily_production_summary` | `{date}` | produÃ§Ã£o, refugo, OEE por mÃ¡quina |
| `daily_downtime_summary` | `{date}` | paradas por tipo, mÃ¡quina, duraÃ§Ã£o |
| `daily_planning_summary` | `{date}` | planos, cumprimento, eficiÃªncia |
| `monthly_kpi_summary` | `{year-month}` | KPIs mensais consolidados |

**Economia estimada:**
- RelatÃ³rio atual: ~500 docs por query Ã— 5 abas Ã— 10 users = ~25.000 leituras/dia
- Com resumo: ~1 doc por query Ã— 5 abas Ã— 10 users = ~50 leituras/dia
- **Economia: ~24.950 leituras/dia (~99.8%)**

**Custos adicionais:**
- Cloud Functions: ~$0.40/milhÃ£o de invocaÃ§Ãµes
- GravaÃ§Ãµes extras: ~100 docs/dia = ~$0.006/dia

**Risco:** Alto â€” requer setup de Cloud Functions, deploy separado, monitoramento

---

### 3.4 ğŸ—ï¸ Implementar `onSnapshot` com `includeMetadataChanges` â†’ ğŸŸ¢ Baixo

**Problema:** Ao reconectar apÃ³s perda de conexÃ£o, `onSnapshot` re-emite todos os documentos, gerando leituras duplicadas.

**SoluÃ§Ã£o:**

```javascript
db.collection('active_downtimes')
    .onSnapshot({ includeMetadataChanges: true }, snapshot => {
        // Ignorar eventos do cache local (nÃ£o sÃ£o leituras reais)
        if (snapshot.metadata.fromCache) return;
        if (!snapshot.metadata.hasPendingWrites) {
            // Apenas processar dados do servidor
            processData(snapshot);
        }
    });
```

**Economia estimada:** ~2.000-5.000 leituras/dia (depende de estabilidade da rede)  
**Risco:** Muito baixo

---

### 3.5 ğŸ—ï¸ Batch reads com `documentId() in` para lookups â†’ ğŸŸ¡ MÃ©dio

**Problema:** VÃ¡rios locais fazem lookups individuais `.doc(id).get()` em loops:

| Arquivo | ColeÃ§Ã£o | PadrÃ£o |
|---------|---------|--------|
| script.js L5099 | `production_orders` | `.doc(orderId).get()` em loop |
| script.js L10122 | `production_orders` | `.doc(orderId).get()` individual |
| script.js L10733 | `production_orders` | `.doc(id).get()` individual |
| script.js L18218 | `production_orders` | `.doc(order_id).get()` individual |

**SoluÃ§Ã£o:** Agrupar IDs e usar `in` query (mÃ¡x 30 por batch):

```javascript
// Em vez de N chamadas individuais:
for (const id of orderIds) {
    const doc = await db.collection('production_orders').doc(id).get();
}

// Fazer uma Ãºnica query batch:
const chunks = chunkArray(orderIds, 30); // Firestore limit: 30 items no 'in'
for (const chunk of chunks) {
    const snapshot = await db.collection('production_orders')
        .where(firebase.firestore.FieldPath.documentId(), 'in', chunk)
        .get();
}
```

**Nota:** `BatchQueryManager` jÃ¡ existe em `script.js` L998 mas Ã© pouco utilizado.

**Economia estimada:** ~5.000-10.000 leituras/dia  
**Risco:** Baixo

---

## NÃVEL 4 â€” OtimizaÃ§Ãµes Arquiteturais (longo prazo)

### 4.1 ğŸ¢ Service Worker com cache offline â†’ ğŸ”´ğŸ”´ Muito Alto

**Problema:** `service-worker.js` existe mas nÃ£o cacheia respostas do Firestore. Cada page reload causa fresh reads.

**SoluÃ§Ã£o:** Implementar estratÃ©gia stale-while-revalidate para dados do Firestore:

```javascript
// service-worker.js â€” interceptar chamadas Firestore REST
self.addEventListener('fetch', event => {
    if (event.request.url.includes('firestore.googleapis.com')) {
        event.respondWith(
            caches.match(event.request).then(cached => {
                const fetchPromise = fetch(event.request).then(response => {
                    const cache = await caches.open('firestore-cache');
                    cache.put(event.request, response.clone());
                    return response;
                });
                return cached || fetchPromise;
            })
        );
    }
});
```

**âš ï¸ Complexidade:** Firestore SDK usa WebSocket/gRPC, nÃ£o REST puro. Esta abordagem funciona apenas com Firestore REST API ou `firebase/firestore/lite`.

**Alternativa mais viÃ¡vel:** Usar `enablePersistence()` do prÃ³prio Firestore SDK:

```javascript
firebase.firestore().enablePersistence({ synchronizeTabs: true })
    .catch(err => console.warn('Persistence failed:', err));
```

**Economia estimada:** ~30-50% em page reloads e reconexÃµes  
**Risco:** MÃ©dio â€” pode causar conflitos de dados em multi-tab

---

### 4.2 ğŸ¢ Migrar para Firestore Lite SDK â†’ ğŸ”´ğŸ”´ Muito Alto

**Problema:** O SDK completo do Firestore inclui cache offline, listeners em tempo real e reconexÃ£o automÃ¡tica â€” funcionalidades pesadas que podem gerar leituras extras durante sincronizaÃ§Ã£o.

**SoluÃ§Ã£o:** Para abas que fazem apenas leituras sob demanda (RelatÃ³rios, AnÃ¡lise, HistÃ³rico), usar `firebase/firestore/lite`:

```javascript
// Firestore Lite â€” ~80% menor, sem overhead de sincronizaÃ§Ã£o
import { getFirestore, collection, getDocs, query, where } 
    from 'firebase/firestore/lite';
```

**BenefÃ­cios:**
- Bundle ~80% menor
- Sem leituras de sincronizaÃ§Ã£o em background
- ConexÃ£o mais rÃ¡pida

**Desvantagens:**
- NÃ£o suporta `onSnapshot` (listeners em tempo real)
- Sem cache offline automÃ¡tico

**Economia estimada:** ~10-15% em leituras de sincronizaÃ§Ã£o  
**Risco:** Alto â€” requer reestruturaÃ§Ã£o significativa do cÃ³digo

---

### 4.3 ğŸ¢ Firestore Bundle (prÃ©-empacotamento server-side) â†’ ğŸ”´ğŸ”´ Muito Alto

**Problema:** Na inicializaÃ§Ã£o, o app lÃª mÃºltiplas coleÃ§Ãµes para popular o estado inicial (~500 leituras).

**SoluÃ§Ã£o:** Usar Firestore Bundles para prÃ©-empacotar dados frequentemente acessados no servidor:

```javascript
// Cloud Function que gera o bundle
exports.createInitBundle = functions.https.onRequest(async (req, res) => {
    const db = admin.firestore();
    const bundleId = `init-${Date.now()}`;
    const bundle = db.bundle(bundleId);
    
    const [planning, orders, downtimes] = await Promise.all([
        db.collection('planning').where('date', '==', today).get(),
        db.collection('production_orders').where('status', '!=', 'finalizada').get(),
        db.collection('active_downtimes').get(),
    ]);
    
    const bundleBuffer = bundle
        .add('planning-today', planning)
        .add('active-orders', orders)
        .add('active-downtimes', downtimes)
        .build();
    
    res.set('Cache-Control', 'public, max-age=300'); // CDN cache 5min
    res.end(bundleBuffer);
});

// Cliente carrega o bundle:
const response = await fetch('/api/initBundle');
const bundle = await response.arrayBuffer();
await db.loadBundle(bundle);
const planningQuery = db.namedQuery('planning-today');
const snapshot = await planningQuery.get({ source: 'cache' }); // 0 reads!
```

**Economia estimada:** ~100% das leituras de inicializaÃ§Ã£o (~500/session Ã— 30 sessions/dia = ~15.000/dia)  
**Risco:** Alto â€” requer Cloud Functions + CDN; bundle pode ficar stale

---

### 4.4 ğŸ¢ Implementar TTL com Firestore TTL Policy â†’ ğŸŸ¢ Baixo

**Problema:** ColeÃ§Ãµes como `system_logs`, `hourly_production_entries` crescem indefinidamente, aumentando o custo de storage e de scans.

**SoluÃ§Ã£o:** Configurar TTL no Firestore Console:

| ColeÃ§Ã£o | Campo TTL | RetenÃ§Ã£o |
|---------|-----------|----------|
| `system_logs` | `timestamp` | 90 dias |
| `hourly_production_entries` | `timestamp` | 30 dias |
| `extended_downtime_logs` (finalizados) | `endTime` | 180 dias |

**ConfiguraÃ§Ã£o:** Firebase Console â†’ Firestore â†’ TTL Policies

**Economia:** ReduÃ§Ã£o de storage + queries mais rÃ¡pidas em coleÃ§Ãµes menores  
**Risco:** Dados antigos sÃ£o permanentemente deletados

---

## ğŸ“Š Matriz de PriorizaÃ§Ã£o

| # | AÃ§Ã£o | EsforÃ§o | Impacto | Economia/Dia | Prioridade |
|---|------|---------|---------|-------------|------------|
| 1.1 | Eliminar full collection reads | âš¡ 2h | ğŸŸ¡ | ~65.000 | **P1** |
| 1.2 | Dashboard TV reutilizar onSnapshot | âš¡ 1h | ğŸŸ¡ | ~2.880 | **P1** |
| 1.3 | Unificar polling duplicado | âš¡ 30min | ğŸŸ¢ | ~8.640 | **P1** |
| 1.4 | visibilitychange no Dashboard TV | âš¡ 30min | ğŸŸ¡ | ~30.000 | **P1** |
| 3.2 | onSnapshot compartilhado active_downtimes | ğŸ—ï¸ 1d | ğŸ”´ | ~16.750 | **P2** |
| 2.1 | InvalidaÃ§Ã£o de cache em writes | ğŸ”§ 4h | ğŸŸ¡ | ~22.500 | **P2** |
| 3.3 | Cloud Functions consolidaÃ§Ã£o | ğŸ—ï¸ 3d | ğŸ”´ | ~24.950 | **P2** |
| 2.2 | Prefetch por aba | ğŸ”§ 4h | ğŸŸ¡ | ~20.000 | **P3** |
| 2.4 | PaginaÃ§Ã£o em coleÃ§Ãµes grandes | ğŸ”§ 6h | ğŸŸ¡ | ~12.000 | **P3** |
| 3.5 | Batch reads com `in` query | ğŸ—ï¸ 4h | ğŸŸ¡ | ~7.500 | **P3** |
| 2.3 | Normalizar perÃ­odos de relatÃ³rios | ğŸ”§ 3h | ğŸŸ¡ | ~15.000 | **P3** |
| 3.4 | onSnapshot com metadata | ğŸ—ï¸ 2h | ğŸŸ¢ | ~3.500 | **P4** |
| 4.1 | enablePersistence | ğŸ¢ 2h | ğŸŸ¡ | ~30.000 | **P4** |
| 4.4 | TTL Policy para logs | ğŸ¢ 1h | ğŸŸ¢ | storage only | **P4** |
| 2.5 | Dashboard monitoramento | ğŸ”§ 4h | ğŸŸ¢ | indireto | **P4** |
| 4.3 | Firestore Bundles | ğŸ¢ 3d | ğŸ”´ | ~15.000 | **P5** |
| 4.2 | Firestore Lite SDK | ğŸ¢ 5d | ğŸŸ¡ | ~10.000 | **P5** |
| 3.1 | Migrar para Realtime DB | ğŸ—ï¸ 3d | âŒ | **NÃƒO recomendado** | â€” |

---

## ğŸ’° ProjeÃ§Ã£o de Economia Consolidada

### CenÃ¡rio Conservador (apenas P1 + P2)

| AÃ§Ã£o | Leituras Eliminadas/Dia |
|------|------------------------|
| Full collection reads eliminados | 65.000 |
| Dashboard TV visibilitychange | 30.000 |
| onSnapshot compartilhado | 16.750 |
| InvalidaÃ§Ã£o de cache em writes | 22.500 |
| Dashboard TV reutilizar onSnapshot | 2.880 |
| Unificar polling | 8.640 |
| **Total eliminado** | **~145.770** |

| MÃ©trica | Atual | Projetado |
|---------|-------|-----------|
| Leituras/dia | ~390.000 | ~244.230 |
| Leituras/mÃªs | ~11.700.000 | ~7.327.000 |
| Custo/mÃªs | ~$12-25 | ~$7-15 |
| **ReduÃ§Ã£o** | â€” | **~37%** |

### CenÃ¡rio Otimista (P1 + P2 + P3 + Cloud Functions)

| MÃ©trica | Atual | Projetado |
|---------|-------|-----------|
| Leituras/dia | ~390.000 | ~130.000 |
| Leituras/mÃªs | ~11.700.000 | ~3.900.000 |
| Custo/mÃªs | ~$12-25 | ~$3-7 |
| **ReduÃ§Ã£o** | â€” | **~67%** |

### CenÃ¡rio MÃ¡ximo (todas as aÃ§Ãµes)

| MÃ©trica | Atual | Projetado |
|---------|-------|-----------|
| Leituras/dia | ~390.000 | ~60.000 |
| Leituras/mÃªs | ~11.700.000 | ~1.800.000 |
| Custo/mÃªs | ~$12-25 | ~$1-3 |
| **ReduÃ§Ã£o** | â€” | **~85-90%** |

---

## ğŸ“ˆ Economia Acumulada HistÃ³rica

| Fase | PerÃ­odo | Antes | Depois | ReduÃ§Ã£o |
|------|---------|-------|--------|---------|
| Original | â€” | 1.200.000/dia | â€” | â€” |
| Fase 1 â€” Duplicatas | Jan/2026 | 1.200.000 | 480.000 | -60% |
| Fase 2 â€” TTLs | Fev/2026 | 480.000 | 390.000 | -19% |
| Fase 3 â€” Cache controllers | Fev/2026 | 390.000 | 390.000 | (jÃ¡ contabilizado) |
| **Fase 4 â€” Este plano (P1-P2)** | **PrÃ³ximo** | **390.000** | **~245.000** | **-37%** |
| **Fase 5 â€” Cloud Functions** | **Futuro** | **245.000** | **~130.000** | **-47%** |
| **TOTAL ACUMULADO** | | **1.200.000** | **~130.000** | **-89%** |

---

## ğŸ” InventÃ¡rio Completo â€” ColeÃ§Ãµes e Uso

| # | ColeÃ§Ã£o | Docs Est. | Readers | Writers | Full Reads | Cacheada |
|---|---------|-----------|---------|---------|------------|----------|
| 1 | `production_entries` | ~10.000+ | 13 files | 3 files | NÃ£o | âœ… Sim |
| 2 | `production_orders` | ~500+ | 7 files | 3 files | **4 locais** | âœ… Sim |
| 3 | `planning` | ~1.000+ | 9 files | 3 files | NÃ£o | âœ… Sim |
| 4 | `active_downtimes` | ~26 | 7 files | 3 files | **10 locais** | âœ… Sim |
| 5 | `downtime_entries` | ~5.000+ | 9 files | 2 files | NÃ£o | âœ… Sim |
| 6 | `extended_downtime_logs` | ~500+ | 3 files | 2 files | NÃ£o | âœ… Sim |
| 7 | `machine_priorities` | ~26 | 4 files | 1 file | **2 locais** | âœ… Sim |
| 8 | `rework_entries` | ~500+ | 2 files | 1 file | NÃ£o | âŒ NÃ£o |
| 9 | `system_logs` | ~50.000+ | 3 files | 1 file | NÃ£o | âŒ NÃ£o |
| 10 | `hourly_production_entries` | ~10.000+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 11 | `quantity_adjustments` | ~200+ | 2 files | 1 file | NÃ£o | âŒ NÃ£o |
| 12 | `escalas_operadores` | ~100+ | 2 files | 1 file | NÃ£o | âŒ NÃ£o |
| 13 | `pmp_borra` | ~200+ | 2 files | 1 file | NÃ£o | âŒ NÃ£o |
| 14 | `pcp_messages` | ~50+ | 2 files | 1 file | NÃ£o | âŒ NÃ£o |
| 15 | `pcp_observations` | ~200+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 16 | `absenteismo` | ~500+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 17 | `acompanhamento_turno` | ~1.000+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 18 | `acompanhamento_perdas` | ~500+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 19 | `ferramentaria_moldes` | ~50+ | 1 file | 1 file | **1 local** | âœ… Sim |
| 20 | `ferramentaria_manutencoes` | ~200+ | 1 file | 1 file | NÃ£o (limit 20) | âŒ NÃ£o |
| 21 | `setups_maquinas` | ~500+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 22 | `pmp_moido` | ~100+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 23 | `pmp_sucata` | ~100+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 24 | `oee_history` | ~1.000+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 25 | `machine_schedule` | ~100+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 26 | `batch_traceability` | ~500+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 27 | `quality_records` | ~200+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 28 | `process_events` | ~1.000+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |
| 29 | `derived_products` | ~100+ | 1 file | 1 file | NÃ£o | âŒ NÃ£o |

---

## âœ… Checklist de ImplementaÃ§Ã£o

### Fase 4A â€” Quick Wins (P1) â€” âš¡ ~4 horas âœ… CONCLUÃDO (Fev/2026)
- [x] Redirecionar full collection reads para funÃ§Ãµes de cache (1.1) â€” `.limit(500)` em `production_orders` (script.js, planning.controller, orders.controller, reports.controller, firebase-cache.service)
- [x] Dashboard TV: reutilizar dados do onSnapshot (1.2) â€” `_activeDowntimesSnapshotData` armazenado no handler, reutilizado em `loadRealTimeData` e `updateRealTimeActiveDowntimes`
- [x] Unificar polling duplicado de active_downtimes (1.3) â€” `planning.controller.js` usa variÃ¡vel separada `_planningDowntimesPolling`, nÃ£o sobrescreve polling do script.js
- [x] Adicionar visibilitychange no Dashboard TV (1.4) â€” pausa/retoma `_dashboardTVPollInterval`
- [x] **EXTRA:** Intervalo de polling do Dashboard TV de 60s â†’ 300s (5 minutos)

### Fase 4B â€” Estruturais (P2) â€” ğŸ”§ ~2 dias
- [ ] Implementar write-invalidation wrapper (2.1)
- [ ] Converter polling de active_downtimes para onSnapshot compartilhado (3.2)
- [ ] Avaliar viabilidade de Cloud Functions (3.3)

### Fase 4C â€” Incrementais (P3) â€” ğŸ”§ ~3 dias
- [ ] Prefetch de dados por aba (2.2)
- [ ] Normalizar perÃ­odos de cache em relatÃ³rios (2.3)
- [ ] PaginaÃ§Ã£o em production_orders (2.4)
- [ ] Batch reads com `in` queries (3.5)

### Fase 4D â€” AvanÃ§adas (P4-P5) â€” ğŸ¢ 1+ semana
- [ ] Dashboard de monitoramento de consumo (2.5)
- [ ] `enablePersistence()` para cache offline (4.1)
- [ ] `onSnapshot` com `includeMetadataChanges` (3.4)
- [ ] TTL Policy para system_logs e hourly_production_entries (4.4)
- [ ] Avaliar Firestore Bundles para init (4.3)
- [ ] Avaliar Firestore Lite para abas read-only (4.2)

---

## âš ï¸ AÃ§Ãµes NÃƒO Recomendadas

| AÃ§Ã£o | Motivo |
|------|--------|
| Migrar `active_downtimes` para Realtime Database | Custo por GB transferido Ã© maior que custo por leitura para esta coleÃ§Ã£o (~26 docs, ~65KB) |
| Remover todos os `onSnapshot` | Listeners sÃ£o eficientes para dados que mudam frequentemente â€” evitam polling |
| TTL muito curto no cache (< 60s) | Causa thrashing â€” mais leituras, nÃ£o menos |
| Desabilitar cache do Firestore SDK | O cache local do SDK evita leituras em reconexÃµes |

---

## ğŸ“š ReferÃªncias

- [OTIMIZACAO-LEITURAS-FIREBASE.md](OTIMIZACAO-LEITURAS-FIREBASE.md) â€” HistÃ³rico de otimizaÃ§Ãµes implementadas
- [ANALISE-OTIMIZACAO-FIREBASE.md](ANALISE-OTIMIZACAO-FIREBASE.md) â€” AnÃ¡lise tÃ©cnica completa
- [ESTUDO-LEITURAS-POR-ABA.md](ESTUDO-LEITURAS-POR-ABA.md) â€” Estudo de consumo por aba
- [Firestore Pricing](https://firebase.google.com/pricing) â€” Modelo de preÃ§os oficial
- [Firestore Best Practices](https://firebase.google.com/docs/firestore/best-practices) â€” Guia oficial

---

*Documento criado em Fevereiro/2026 â€” Sistema MES Hokkaido*
*Baseado em auditoria completa do cÃ³digo-fonte com 29 coleÃ§Ãµes e ~115 chamadas `.get()` identificadas*
